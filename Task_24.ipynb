{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMKxp+Q7E3NZiQAv1wGGOM2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayesha-119/Deep-Learning-BWF/blob/master/Task_24.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ðŸ”´ Task 24**\n",
        "\n",
        "**Topics: Data Preprocessing and Feature Engineering**\n",
        "\n",
        "Resource: https://drive.google.com/file/d/1i9dPxM_1M4HYN5bYxFcuklC1vM0GrOCq/view?usp=share_link"
      ],
      "metadata": {
        "id": "0xqJepGaLFiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Preprocessing for Neural Networks:**\n",
        "\n",
        "\n",
        "\n",
        "1.   **Vectorization:**\n",
        "\n",
        "\n",
        ">\n",
        "\n",
        "*   Neural networks require data to be in numerical form, so categorical variables need to be converted into numerical representations.\n",
        "\n",
        "*   One-hot encoding is commonly used to convert categorical variables into binary vectors.\n",
        "*   Continuous variables can be used as they are, but they may need normalization (step 2) for better convergence.\n",
        "\n",
        "\n",
        "2.  **Value Normalization:**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*    Normalization helps bring different features into a similar scale and range.\n",
        "*   Common techniques include min-max scaling (scaling values between 0 and 1) and z-score normalization (scaling values to have zero mean and unit variance).\n",
        "*   Common techniques include min-max scaling (scaling values between 0 and 1) and z-score normalization (scaling values to have zero mean and unit variance).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "3.  **Handling Missing Values:**\n",
        "\n",
        "\n",
        "\n",
        "*   Missing data can significantly affect the performance of neural networks.\n",
        "One approach is to remove instances with missing values, but this can lead to data loss.\n",
        "*   Alternatively, missing values can be imputed (replaced) using techniques like mean imputation, median imputation, or regression imputation.\n",
        "*   Another option is to create an indicator variable that flags missing values, allowing the model to learn patterns related to missingness.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vnM8yyNmexoQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Feature engineering**\n",
        "\n",
        "\n",
        "*   Feature engineering is the process of simplifying a problem by transforming the data into a more suitable representation for a machine learning algorithm.\n",
        "\n",
        "*   It involves applying hardcoded (nonlearned) transformations to the data based on domain knowledge and understanding of the problem.\n",
        "\n",
        "*   Before deep learning, feature engineering was critical because shallow algorithms lacked the ability to learn useful features on their own.\n",
        "\n",
        "*   Deep learning models can automatically extract features from raw data, reducing the need for extensive feature engineering.\n",
        "*   However, feature engineering still has its importance:\n",
        "Good features allow for more elegant solutions and efficient resource utilization.\n",
        "\n",
        "  *   Good features allow for more elegant solutions and efficient resource utilization.\n",
        "  *   Good features become crucial when dealing with limited training data.\n",
        "\n",
        "*   Well-designed features can make a problem easier and enable simpler machine learning algorithms to solve it effectively.\n",
        "\n",
        "\n",
        "*   Deep learning models can benefit from feature engineering in scenarios where using raw data might be impractical or inefficient.\n",
        "\n",
        "\n",
        "*   Feature engineering requires a deep understanding of the problem and the data to create informative and meaningful features."
      ],
      "metadata": {
        "id": "8Ej1i8lhhK5S"
      }
    }
  ]
}